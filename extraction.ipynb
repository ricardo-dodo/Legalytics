{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# For NLP\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "flat_data = json_normalize(data, record_path=['data']) # flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>type</th>\n",
       "      <th>bab</th>\n",
       "      <th>bagian</th>\n",
       "      <th>paragraf</th>\n",
       "      <th>pasal</th>\n",
       "      <th>level</th>\n",
       "      <th>context</th>\n",
       "      <th>additional_context</th>\n",
       "      <th>chunks</th>\n",
       "      <th>source_token_length</th>\n",
       "      <th>buku</th>\n",
       "      <th>alias</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERITA NEGARA REPUBLIK INDONESIA No.920, 2017 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERATURAN MENTERI KEUANGAN REPUBLIK INDONESIA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DENGAN RAHMAT TUHAN YANG MAHA ESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MENTERI KEUANGAN REPUBLIK INDONESIA,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>SRI MULYANI INDRAWATI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>Diundangkan di Jakarta pada tanggal 7 Juli 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>DIREKTUR JENDERAL PERATURAN PERUNDANG-UNDANGAN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>ttd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>WIDODO EKATJAHJANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2347 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content   id  ref type  bab  \\\n",
       "0                                                        NaN  NaN  NaN  NaN   \n",
       "1     BERITA NEGARA REPUBLIK INDONESIA No.920, 2017 ...  NaN  NaN  NaN  NaN   \n",
       "2     PERATURAN MENTERI KEUANGAN REPUBLIK INDONESIA ...  NaN  NaN  NaN  NaN   \n",
       "3                     DENGAN RAHMAT TUHAN YANG MAHA ESA  NaN  NaN  NaN  NaN   \n",
       "4                  MENTERI KEUANGAN REPUBLIK INDONESIA,  NaN  NaN  NaN  NaN   \n",
       "...                                                 ...  ...  ...  ...  ...   \n",
       "2342                              SRI MULYANI INDRAWATI  NaN  NaN  NaN  NaN   \n",
       "2343    Diundangkan di Jakarta pada tanggal 7 Juli 2017  NaN  NaN  NaN  NaN   \n",
       "2344  DIREKTUR JENDERAL PERATURAN PERUNDANG-UNDANGAN...  NaN  NaN  NaN  NaN   \n",
       "2345                                                ttd  NaN  NaN  NaN  NaN   \n",
       "2346                                 WIDODO EKATJAHJANA  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     bagian  paragraf pasal  level context additional_context chunks  \\\n",
       "0       NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "1       NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "2       NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "3       NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "4       NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "...     ...       ...   ...    ...     ...                ...    ...   \n",
       "2342    NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "2343    NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "2344    NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "2345    NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "2346    NaN       NaN   NaN    NaN     NaN                NaN    NaN   \n",
       "\n",
       "      source_token_length  buku alias term  \n",
       "0                     NaN   NaN   NaN  NaN  \n",
       "1                     NaN   NaN   NaN  NaN  \n",
       "2                     NaN   NaN   NaN  NaN  \n",
       "3                     NaN   NaN   NaN  NaN  \n",
       "4                     NaN   NaN   NaN  NaN  \n",
       "...                   ...   ...   ...  ...  \n",
       "2342                  NaN   NaN   NaN  NaN  \n",
       "2343                  NaN   NaN   NaN  NaN  \n",
       "2344                  NaN   NaN   NaN  NaN  \n",
       "2345                  NaN   NaN   NaN  NaN  \n",
       "2346                  NaN   NaN   NaN  NaN  \n",
       "\n",
       "[2347 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2347 entries, 0 to 2346\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   content              2347 non-null   object \n",
      " 1   id                   1153 non-null   object \n",
      " 2   ref                  1201 non-null   object \n",
      " 3   type                 2044 non-null   object \n",
      " 4   bab                  1524 non-null   object \n",
      " 5   bagian               126 non-null    object \n",
      " 6   paragraf             0 non-null      float64\n",
      " 7   pasal                1533 non-null   object \n",
      " 8   level                1153 non-null   float64\n",
      " 9   context              801 non-null    object \n",
      " 10  additional_context   801 non-null    object \n",
      " 11  chunks               891 non-null    object \n",
      " 12  source_token_length  801 non-null    float64\n",
      " 13  buku                 0 non-null      float64\n",
      " 14  alias                90 non-null     object \n",
      " 15  term                 90 non-null     object \n",
      "dtypes: float64(4), object(12)\n",
      "memory usage: 293.5+ KB\n"
     ]
    }
   ],
   "source": [
    "flat_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-522M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Set up the IndoBERT NER model\n",
    "model_name = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=\"cahya/bert-base-indonesian-522M\", tokenizer=\"cahya/bert-base-indonesian-522M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prohibitions(text):\n",
    "    \"\"\"\n",
    "    Extracts the list of prohibitions from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to extract the prohibitions.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of prohibitions extracted from the text.\n",
    "    \"\"\"\n",
    "    prohibition_pattern = re.compile(r'\\bDilarang:\\s*([^;]+)', re.IGNORECASE)\n",
    "    prohibitions = prohibition_pattern.findall(text)\n",
    "    return prohibitions\n",
    "\n",
    "def extract_dates(text):\n",
    "    \"\"\"\n",
    "    Extracts dates from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which dates need to be extracted.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dates extracted from the text.\n",
    "    \"\"\"\n",
    "    date_pattern = re.compile(r'\\b(?:\\d{1,2}\\s(?:Januari|Februari|Maret|April|Mei|Juni|Juli|Agustus|September|Oktober|November|Desember)\\s\\d{4})\\b')\n",
    "    return date_pattern.findall(text)\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_money(text):\n",
    "    \"\"\"\n",
    "    Extracts money or monetary keywords from the given text, including multiple currencies.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to extract money or monetary keywords.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of money or monetary keywords extracted from the text, including Rupiah, USD, and other major currencies.\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        'RP': re.compile(r'\\b(?:\\(?Rp\\s*(?:\\d{1,3}(?:[,.]\\d{3})*(?:\\.\\d+)?|\\d+(?:\\.\\d+)?)\\)?|\\(?Rp\\s*(?:nol|nol,? nol)\\)?\\s*\\(?Rupiah\\)?)\\b', re.IGNORECASE),\n",
    "        'USD': re.compile(r\"(USD)([+-]?[0-9]{1,3}(,?[0-9]{3})*)(\\.[0-9]{1,4})\"),\n",
    "        'EUR': re.compile(r\"(€|EUR)([+-]?[0-9]{1,3}(,?[0-9]{3})*)(\\.[0-9]{1,4})\"),\n",
    "        'GBP': re.compile(r\"(£|GBP)([+-]?[0-9]{1,3}(,?[0-9]{3})*)(\\.[0-9]{1,4})\"),\n",
    "        'JPY': re.compile(r\"(¥|JPY)([+-]?[0-9]{1,3}(,?[0-9]{3})*)(\\.?[0-9]{0,4})\"),  # Yen typically doesn't use decimal places for common transactions\n",
    "    }\n",
    "\n",
    "    matches = []\n",
    "    for currency, pattern in patterns.items():\n",
    "        found_matches = pattern.findall(text)\n",
    "        for match in found_matches:\n",
    "            matches.append(''.join(match))\n",
    "\n",
    "    # Convert word numbers to digits for Rupiah\n",
    "    word_to_number = {\n",
    "        'satu': '1', 'dua': '2', 'tiga': '3', 'empat': '4', 'lima': '5',\n",
    "        'enam': '6', 'tujuh': '7', 'delapan': '8', 'sembilan': '9', 'nol': '0',\n",
    "        'ribu': '000', 'juta': '000000', 'miliar': '000000000', 'triliun': '000000000000'\n",
    "    }\n",
    "\n",
    "    numerical_matches = []\n",
    "    for match in matches:\n",
    "        for word, value in word_to_number.items():\n",
    "            if 'Rp' in match:  # Apply word-to-number conversion only for Rupiah\n",
    "                match = match.replace(word, value)\n",
    "        numerical_matches.append(match)\n",
    "\n",
    "    return numerical_matches\n",
    "\n",
    "\n",
    "def apply_ner(text, ner_pipeline, max_length=512):\n",
    "    \"\"\"Apply Named Entity Recognition (NER) using the transformers pipeline on the given text.\n",
    "    This version supports processing of text longer than 512 tokens by splitting the text into\n",
    "    manageable parts and then combining the results.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to perform NER on.\n",
    "        ner_pipeline (pipeline): The NER pipeline for prediction.\n",
    "        max_length (int): Maximum length of tokens to process in a single call to the NER pipeline.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of predicted named entities in the text.\n",
    "    \"\"\"\n",
    "    if not text.strip():  # Check if text is empty\n",
    "        return []\n",
    "\n",
    "    # Initialize variables\n",
    "    split_texts = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "    ner_results = []\n",
    "\n",
    "    # Process each split text\n",
    "    for split_text in split_texts:\n",
    "        results = ner_pipeline(split_text)\n",
    "        ner_results.extend(results)\n",
    "\n",
    "    return ner_results\n",
    "\n",
    "\n",
    "flat_data = flat_data.dropna(subset=['content'])\n",
    "\n",
    "def process_record(record, ner_pipeline):\n",
    "    \"\"\"Process a record by extracting relevant information.\n",
    "\n",
    "    Args:\n",
    "        record (pd.Series): A pandas Series representing a record with 'content' as one of the keys.\n",
    "        ner_pipeline: The NER pipeline object used for Named Entity Recognition.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the processed record with the following keys:\n",
    "            - 'content': The original content of the record.\n",
    "            - 'money': A list of extracted money values.\n",
    "            - 'dates': A list of extracted dates.\n",
    "            - 'prohibitions': A list of extracted prohibitions.\n",
    "            - 'named_entities': A list of named entities recognized by NER.\n",
    "    \"\"\"\n",
    "    content = record['content']\n",
    "\n",
    "    if not content:\n",
    "        return {\n",
    "            'content': content,\n",
    "            'money': [],\n",
    "            'dates': [],\n",
    "            'prohibitions': [],\n",
    "            'named_entities': []\n",
    "        }\n",
    "\n",
    "    result_dict = {\n",
    "        'content': content,\n",
    "        'money': extract_money(content),\n",
    "        'dates': extract_dates(content),\n",
    "        'prohibitions': extract_prohibitions(content),\n",
    "    }\n",
    "    ner_results = apply_ner(content, ner_pipeline)\n",
    "\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content money          dates  \\\n",
      "0                                                          []             []   \n",
      "1     BERITA NEGARA REPUBLIK INDONESIA No.920, 2017 ...    []             []   \n",
      "2     PERATURAN MENTERI KEUANGAN REPUBLIK INDONESIA ...    []             []   \n",
      "3                     DENGAN RAHMAT TUHAN YANG MAHA ESA    []             []   \n",
      "4                  MENTERI KEUANGAN REPUBLIK INDONESIA,    []             []   \n",
      "...                                                 ...   ...            ...   \n",
      "2342                              SRI MULYANI INDRAWATI    []             []   \n",
      "2343    Diundangkan di Jakarta pada tanggal 7 Juli 2017    []  [7 Juli 2017]   \n",
      "2344  DIREKTUR JENDERAL PERATURAN PERUNDANG-UNDANGAN...    []             []   \n",
      "2345                                                ttd    []             []   \n",
      "2346                                 WIDODO EKATJAHJANA    []             []   \n",
      "\n",
      "     prohibitions named_entities  \n",
      "0              []            NaN  \n",
      "1              []            NaN  \n",
      "2              []            NaN  \n",
      "3              []            NaN  \n",
      "4              []            NaN  \n",
      "...           ...            ...  \n",
      "2342           []            NaN  \n",
      "2343           []            NaN  \n",
      "2344           []            NaN  \n",
      "2345           []            NaN  \n",
      "2346           []            NaN  \n",
      "\n",
      "[2347 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have a DataFrame 'flat_data' with a 'content' column available.\n",
    "# Create a new DataFrame to store the processed records\n",
    "processed_records = [process_record(row, ner_pipeline) for index, row in flat_data.iterrows()]\n",
    "processed_df = pd.DataFrame(processed_records)\n",
    "\n",
    "# Now `processed_df` contains the original content and the extracted information.\n",
    "print(processed_df)  # To inspect the first few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop named_entities column\n",
    "# processed_df = processed_df.drop(columns='named_entities')\n",
    "for col in processed_df.columns:\n",
    "    processed_df[col] = processed_df[col].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in money column:\n",
      "['' 'Rp0, Rp0']\n",
      "\n",
      "Unique values in dates column:\n",
      "['' '8 Juni 2017' '5 Juli 2017' '7 Juli 2017' '16 Januari 2023'\n",
      " '17 Januari 2023' '23 April 2019' '18 Oktober 2019']\n",
      "\n",
      "Unique values in prohibitions column:\n",
      "[''\n",
      " 'a. menggunakan kewenangan yang dimiliki untuk kepentingan pribadi, keluarga, dan/atau golongan']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#unique column money, dates, prohibitions and print all of them with for loop\n",
    "for col in ['money', 'dates', 'prohibitions']:\n",
    "    print(f'Unique values in {col} column:')\n",
    "    print(processed_df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
